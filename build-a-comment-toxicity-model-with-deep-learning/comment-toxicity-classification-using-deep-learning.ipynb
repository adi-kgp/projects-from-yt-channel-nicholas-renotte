{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a127f42-4103-442d-8be4-8f91eea3816f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comment Toxicity Classification using Deep Learning\n",
    "\n",
    "Data source : https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data?select=train.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a5d9e3-94cb-4677-9777-7f4c33f322da",
   "metadata": {},
   "source": [
    "### 0. Install Dependencies and Bring in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1448276-db2e-45f9-a436-87a7ffe0e736",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 15:03:12.324812: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f424b0b4-6c25-42f3-9c4c-e8c8b5d6f6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('data', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e70dc2e-1a39-4f91-8692-6a9cef0e2d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nMore\\nI can\\'t make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It\\'s listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d361de1-6b37-4303-9eb4-f81433b8af26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            1\n",
       "severe_toxic     1\n",
       "obscene          1\n",
       "threat           0\n",
       "insult           1\n",
       "identity_hate    0\n",
       "Name: 6, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[2:]].iloc[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7564ff2e-684b-41be-9369-73f486dc766d",
   "metadata": {},
   "source": [
    "### 1. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d51aafd6-315c-4a68-9a48-e02928cec8da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f0ef2a4-dc44-4e0a-b033-c0f33d6ea20b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mTextVectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstandardize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lower_and_strip_punctuation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'whitespace'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mngrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_sequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpad_to_max_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0midf_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mragged\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A preprocessing layer which maps text features to integer sequences.\n",
       "\n",
       "This layer has basic options for managing text in a Keras model. It\n",
       "transforms a batch of strings (one example = one string) into either a list\n",
       "of token indices (one example = 1D tensor of integer token indices) or a\n",
       "dense representation (one example = 1D tensor of float values representing\n",
       "data about the example's tokens). This layer is meant to handle natural\n",
       "language inputs. To handle simple string inputs (categorical strings or\n",
       "pre-tokenized strings) see `tf.keras.layers.StringLookup`.\n",
       "\n",
       "The vocabulary for the layer must be either supplied on construction or\n",
       "learned via `adapt()`. When this layer is adapted, it will analyze the\n",
       "dataset, determine the frequency of individual string values, and create a\n",
       "vocabulary from them. This vocabulary can have unlimited size or be capped,\n",
       "depending on the configuration options for this layer; if there are more\n",
       "unique values in the input than the maximum vocabulary size, the most\n",
       "frequent terms will be used to create the vocabulary.\n",
       "\n",
       "The processing of each example contains the following steps:\n",
       "\n",
       "1. Standardize each example (usually lowercasing + punctuation stripping)\n",
       "2. Split each example into substrings (usually words)\n",
       "3. Recombine substrings into tokens (usually ngrams)\n",
       "4. Index tokens (associate a unique int value with each token)\n",
       "5. Transform each example using this index, either into a vector of ints or\n",
       "   a dense float vector.\n",
       "\n",
       "Some notes on passing callables to customize splitting and normalization for\n",
       "this layer:\n",
       "\n",
       "1. Any callable can be passed to this Layer, but if you want to serialize\n",
       "   this object you should only pass functions that are registered Keras\n",
       "   serializables (see `tf.keras.utils.register_keras_serializable` for more\n",
       "   details).\n",
       "2. When using a custom callable for `standardize`, the data received\n",
       "   by the callable will be exactly as passed to this layer. The callable\n",
       "   should return a tensor of the same shape as the input.\n",
       "3. When using a custom callable for `split`, the data received by the\n",
       "   callable will have the 1st dimension squeezed out - instead of\n",
       "   `[[\"string to split\"], [\"another string to split\"]]`, the Callable will\n",
       "   see `[\"string to split\", \"another string to split\"]`. The callable should\n",
       "   return a Tensor with the first dimension containing the split tokens -\n",
       "   in this example, we should see something like `[[\"string\", \"to\",\n",
       "   \"split\"], [\"another\", \"string\", \"to\", \"split\"]]`. This makes the callable\n",
       "   site natively compatible with `tf.strings.split()`.\n",
       "\n",
       "For an overview and full list of preprocessing layers, see the preprocessing\n",
       "[guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
       "\n",
       "Args:\n",
       "  max_tokens: Maximum size of the vocabulary for this layer. This should\n",
       "    only be specified when adapting a vocabulary or when setting\n",
       "    `pad_to_max_tokens=True`. Note that this vocabulary\n",
       "    contains 1 OOV token, so the effective number of tokens is\n",
       "    `(max_tokens - 1 - (1 if output_mode == \"int\" else 0))`.\n",
       "  standardize: Optional specification for standardization to apply to the\n",
       "    input text. Values can be:\n",
       "      - `None`: No standardization.\n",
       "      - `\"lower_and_strip_punctuation\"`: Text will be lowercased and all\n",
       "        punctuation removed.\n",
       "      - `\"lower\"`: Text will be lowercased.\n",
       "      - `\"strip_punctuation\"`: All punctuation will be removed.\n",
       "      - Callable: Inputs will passed to the callable function, which should\n",
       "        standardized and returned.\n",
       "  split: Optional specification for splitting the input text. Values can be:\n",
       "      - `None`: No splitting.\n",
       "      - `\"whitespace\"`: Split on whitespace.\n",
       "      - `\"character\"`: Split on each unicode character.\n",
       "      - Callable: Standardized inputs will passed to the callable function,\n",
       "        which should split and returned.\n",
       "  ngrams: Optional specification for ngrams to create from the\n",
       "    possibly-split input text. Values can be None, an integer or tuple of\n",
       "    integers; passing an integer will create ngrams up to that integer, and\n",
       "    passing a tuple of integers will create ngrams for the specified values\n",
       "    in the tuple. Passing None means that no ngrams will be created.\n",
       "  output_mode: Optional specification for the output of the layer. Values\n",
       "    can be `\"int\"`, `\"multi_hot\"`, `\"count\"` or `\"tf_idf\"`, configuring the\n",
       "    layer as follows:\n",
       "      - `\"int\"`: Outputs integer indices, one integer index per split string\n",
       "        token. When `output_mode == \"int\"`, 0 is reserved for masked\n",
       "        locations; this reduces the vocab size to\n",
       "        `max_tokens - 2` instead of `max_tokens - 1`.\n",
       "      - `\"multi_hot\"`: Outputs a single int array per batch, of either\n",
       "        vocab_size or max_tokens size, containing 1s in all elements where\n",
       "        the token mapped to that index exists at least once in the batch\n",
       "        item.\n",
       "      - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a count of\n",
       "        the number of times the token at that index appeared in the\n",
       "        batch item.\n",
       "      - `\"tf_idf\"`: Like `\"multi_hot\"`, but the TF-IDF algorithm is applied\n",
       "        to find the value in each token slot.\n",
       "    For `\"int\"` output, any shape of input and output is supported. For all\n",
       "    other output modes, currently only rank 1 inputs (and rank 2 outputs\n",
       "    after splitting) are supported.\n",
       "  output_sequence_length: Only valid in INT mode. If set, the output will\n",
       "    have its time dimension padded or truncated to exactly\n",
       "    `output_sequence_length` values, resulting in a tensor of shape\n",
       "    `(batch_size, output_sequence_length)` regardless of how many tokens\n",
       "    resulted from the splitting step. Defaults to None.\n",
       "  pad_to_max_tokens: Only valid in  `\"multi_hot\"`, `\"count\"`, and `\"tf_idf\"`\n",
       "    modes. If True, the output will have its feature axis padded to\n",
       "    `max_tokens` even if the number of unique tokens in the vocabulary is\n",
       "    less than max_tokens, resulting in a tensor of shape `(batch_size,\n",
       "    max_tokens)` regardless of vocabulary size. Defaults to False.\n",
       "  vocabulary: Optional. Either an array of strings or a string path to a\n",
       "    text file. If passing an array, can pass a tuple, list, 1D numpy array,\n",
       "    or 1D tensor containing the string vocbulary terms. If passing a file\n",
       "    path, the file should contain one line per term in the vocabulary. If\n",
       "    this argument is set, there is no need to `adapt()` the layer.\n",
       "  idf_weights: Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list,\n",
       "    1D numpy array, or 1D tensor or the same length as the vocabulary,\n",
       "    containing the floating point inverse document frequency weights, which\n",
       "    will be multiplied by per sample term counts for the final `tf_idf`\n",
       "    weight. If the `vocabulary` argument is set, and `output_mode` is\n",
       "    `\"tf_idf\"`, this argument must be supplied.\n",
       "  ragged: Boolean. Only applicable to `\"int\"` output mode. If True, returns\n",
       "    a `RaggedTensor` instead of a dense `Tensor`, where each sequence may\n",
       "    have a different length after string splitting. Defaults to False.\n",
       "  sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n",
       "    `\"tf_idf\"` output modes. If True, returns a `SparseTensor` instead of a\n",
       "    dense `Tensor`. Defaults to False.\n",
       "\n",
       "Example:\n",
       "\n",
       "This example instantiates a `TextVectorization` layer that lowercases text,\n",
       "splits on whitespace, strips punctuation, and outputs integer vocab indices.\n",
       "\n",
       ">>> text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
       ">>> max_features = 5000  # Maximum vocab size.\n",
       ">>> max_len = 4  # Sequence length to pad the outputs to.\n",
       ">>>\n",
       ">>> # Create the layer.\n",
       ">>> vectorize_layer = tf.keras.layers.TextVectorization(\n",
       "...  max_tokens=max_features,\n",
       "...  output_mode='int',\n",
       "...  output_sequence_length=max_len)\n",
       ">>>\n",
       ">>> # Now that the vocab layer has been created, call `adapt` on the\n",
       ">>> # text-only dataset to create the vocabulary. You don't have to batch,\n",
       ">>> # but for large datasets this means we're not keeping spare copies of\n",
       ">>> # the dataset.\n",
       ">>> vectorize_layer.adapt(text_dataset.batch(64))\n",
       ">>>\n",
       ">>> # Create the model that uses the vectorize text layer\n",
       ">>> model = tf.keras.models.Sequential()\n",
       ">>>\n",
       ">>> # Start by creating an explicit input layer. It needs to have a shape of\n",
       ">>> # (1,) (because we need to guarantee that there is exactly one string\n",
       ">>> # input per batch), and the dtype needs to be 'string'.\n",
       ">>> model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
       ">>>\n",
       ">>> # The first layer in our model is the vectorization layer. After this\n",
       ">>> # layer, we have a tensor of shape (batch_size, max_len) containing\n",
       ">>> # vocab indices.\n",
       ">>> model.add(vectorize_layer)\n",
       ">>>\n",
       ">>> # Now, the model can map strings to integers, and you can add an\n",
       ">>> # embedding layer to map these integers to learned embeddings.\n",
       ">>> input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
       ">>> model.predict(input_data)\n",
       "array([[2, 1, 4, 0],\n",
       "       [1, 3, 0, 0]])\n",
       "\n",
       "Example:\n",
       "\n",
       "This example instantiates a `TextVectorization` layer by passing a list\n",
       "of vocabulary terms to the layer's `__init__()` method.\n",
       "\n",
       ">>> vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n",
       ">>> max_len = 4  # Sequence length to pad the outputs to.\n",
       ">>>\n",
       ">>> # Create the layer, passing the vocab directly. You can also pass the\n",
       ">>> # vocabulary arg a path to a file containing one vocabulary word per\n",
       ">>> # line.\n",
       ">>> vectorize_layer = tf.keras.layers.TextVectorization(\n",
       "...  max_tokens=max_features,\n",
       "...  output_mode='int',\n",
       "...  output_sequence_length=max_len,\n",
       "...  vocabulary=vocab_data)\n",
       ">>>\n",
       ">>> # Because we've passed the vocabulary directly, we don't need to adapt\n",
       ">>> # the layer - the vocabulary is already set. The vocabulary contains the\n",
       ">>> # padding token ('') and OOV token ('[UNK]') as well as the passed\n",
       ">>> # tokens.\n",
       ">>> vectorize_layer.get_vocabulary()\n",
       "['', '[UNK]', 'earth', 'wind', 'and', 'fire']\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/dl-env/lib/python3.10/site-packages/keras/layers/preprocessing/text_vectorization.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TextVectorization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bbeb76b-08d4-47dc-88e3-eb1f146029a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['comment_text']\n",
    "y = df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "367d0c1a-f6b7-4d38-bbfd-b36e04b25f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cb88485-2836-4e5f-ba93-e75e49038520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Explanation\\nWhy the edits made under my usern...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "                                ...                        \n",
       "159566    \":::::And for the second time of asking, when ...\n",
       "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
       "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
       "159569    And it looks like it was actually you who put ...\n",
       "159570    \"\\nAnd ... I really don't think you understand...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8908fb5-4370-4018-a4a6-2db28271c18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665d6281-b15a-4ef6-9d39-8c8668b49aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Explanation\\nWhy the edits made under my usern...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "                                ...                        \n",
       "159566    \":::::And for the second time of asking, when ...\n",
       "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
       "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
       "159569    And it looks like it was actually you who put ...\n",
       "159570    \"\\nAnd ... I really don't think you understand...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dd24c89-e277-4575-bc19-3f9e788fb3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9304419-a934-47e9-a79c-6469c152db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 1000 # number of words in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5bab08ab-2a90-4959-a0db-3a760faf681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
    "                           output_sequence_length=100,\n",
    "                           output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "795226fd-082a-43c0-9b0d-b102eb13938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c46fabd2-10f9-467e-8262-d8f1a7a31cb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'the',\n",
       " 'to',\n",
       " 'of',\n",
       " 'and',\n",
       " 'a',\n",
       " 'you',\n",
       " 'i',\n",
       " 'is',\n",
       " 'that',\n",
       " 'in',\n",
       " 'it',\n",
       " 'for',\n",
       " 'this',\n",
       " 'not',\n",
       " 'on',\n",
       " 'be',\n",
       " 'as',\n",
       " 'have',\n",
       " 'are',\n",
       " 'your',\n",
       " 'with',\n",
       " 'if',\n",
       " 'article',\n",
       " 'was',\n",
       " 'or',\n",
       " 'but',\n",
       " 'page',\n",
       " 'my',\n",
       " 'an',\n",
       " 'from',\n",
       " 'by',\n",
       " 'do',\n",
       " 'at',\n",
       " 'about',\n",
       " 'me',\n",
       " 'so',\n",
       " 'wikipedia',\n",
       " 'can',\n",
       " 'what',\n",
       " 'there',\n",
       " 'all',\n",
       " 'has',\n",
       " 'will',\n",
       " 'talk',\n",
       " 'please',\n",
       " 'would',\n",
       " 'its',\n",
       " 'no',\n",
       " 'one',\n",
       " 'just',\n",
       " 'like',\n",
       " 'they',\n",
       " 'he',\n",
       " 'dont',\n",
       " 'which',\n",
       " 'any',\n",
       " 'been',\n",
       " 'should',\n",
       " 'more',\n",
       " 'we',\n",
       " 'some',\n",
       " 'other',\n",
       " 'who',\n",
       " 'see',\n",
       " 'here',\n",
       " 'also',\n",
       " 'his',\n",
       " 'think',\n",
       " 'im',\n",
       " 'because',\n",
       " 'know',\n",
       " 'how',\n",
       " 'am',\n",
       " 'people',\n",
       " 'why',\n",
       " 'edit',\n",
       " 'articles',\n",
       " 'only',\n",
       " 'out',\n",
       " 'up',\n",
       " 'when',\n",
       " 'were',\n",
       " 'use',\n",
       " 'then',\n",
       " 'may',\n",
       " 'time',\n",
       " 'did',\n",
       " 'them',\n",
       " 'now',\n",
       " 'being',\n",
       " 'their',\n",
       " 'than',\n",
       " 'thanks',\n",
       " 'even',\n",
       " 'get',\n",
       " 'make',\n",
       " 'good',\n",
       " 'had',\n",
       " 'very',\n",
       " 'information',\n",
       " 'does',\n",
       " 'could',\n",
       " 'well',\n",
       " 'want',\n",
       " 'such',\n",
       " 'sources',\n",
       " 'way',\n",
       " 'name',\n",
       " 'these',\n",
       " 'deletion',\n",
       " 'pages',\n",
       " 'first',\n",
       " 'help',\n",
       " 'new',\n",
       " 'editing',\n",
       " 'source',\n",
       " 'go',\n",
       " 'need',\n",
       " 'say',\n",
       " 'section',\n",
       " 'edits',\n",
       " 'again',\n",
       " 'thank',\n",
       " 'where',\n",
       " 'user',\n",
       " 'made',\n",
       " 'many',\n",
       " 'much',\n",
       " 'really',\n",
       " 'used',\n",
       " 'most',\n",
       " 'discussion',\n",
       " 'find',\n",
       " 'same',\n",
       " 'ive',\n",
       " 'deleted',\n",
       " 'into',\n",
       " 'fuck',\n",
       " 'those',\n",
       " 'work',\n",
       " 'since',\n",
       " 'before',\n",
       " 'after',\n",
       " 'point',\n",
       " 'add',\n",
       " 'look',\n",
       " 'right',\n",
       " 'read',\n",
       " 'image',\n",
       " 'take',\n",
       " 'still',\n",
       " 'over',\n",
       " 'someone',\n",
       " 'him',\n",
       " 'two',\n",
       " 'back',\n",
       " 'too',\n",
       " 'fact',\n",
       " 'link',\n",
       " 'said',\n",
       " 'own',\n",
       " 'something',\n",
       " 'going',\n",
       " 'youre',\n",
       " 'blocked',\n",
       " 'list',\n",
       " 'stop',\n",
       " 'without',\n",
       " 'content',\n",
       " 'hi',\n",
       " 'under',\n",
       " 'editors',\n",
       " 'our',\n",
       " 'block',\n",
       " 'thats',\n",
       " 'us',\n",
       " 'added',\n",
       " 'utc',\n",
       " 'history',\n",
       " 'another',\n",
       " 'doesnt',\n",
       " 'removed',\n",
       " 'might',\n",
       " 'note',\n",
       " 'however',\n",
       " 'sure',\n",
       " 'place',\n",
       " 'never',\n",
       " 'done',\n",
       " 'welcome',\n",
       " 'her',\n",
       " 'case',\n",
       " 'put',\n",
       " 'personal',\n",
       " 'seems',\n",
       " 'reason',\n",
       " 'better',\n",
       " 'using',\n",
       " 'yourself',\n",
       " 'cant',\n",
       " 'actually',\n",
       " 'ask',\n",
       " 'comment',\n",
       " 'while',\n",
       " 'vandalism',\n",
       " 'feel',\n",
       " 'question',\n",
       " 'anything',\n",
       " 'believe',\n",
       " 'person',\n",
       " 'links',\n",
       " 'things',\n",
       " 'both',\n",
       " 'didnt',\n",
       " 'comments',\n",
       " 'best',\n",
       " 'ill',\n",
       " 'part',\n",
       " 'she',\n",
       " 'hope',\n",
       " 'policy',\n",
       " 'against',\n",
       " 'off',\n",
       " 'keep',\n",
       " 'already',\n",
       " 'free',\n",
       " 'wiki',\n",
       " 'thing',\n",
       " 'nothing',\n",
       " 'change',\n",
       " 'wrong',\n",
       " 'though',\n",
       " 'problem',\n",
       " 'remove',\n",
       " 'little',\n",
       " 'subject',\n",
       " '•',\n",
       " 'others',\n",
       " 'trying',\n",
       " 'tag',\n",
       " 'copyright',\n",
       " 'must',\n",
       " 'understand',\n",
       " 'above',\n",
       " 'few',\n",
       " 'anyone',\n",
       " 'speedy',\n",
       " 'last',\n",
       " 'issue',\n",
       " 'give',\n",
       " 'questions',\n",
       " 'agree',\n",
       " 'rather',\n",
       " 'years',\n",
       " 'let',\n",
       " '2',\n",
       " 'different',\n",
       " 'editor',\n",
       " 'long',\n",
       " 'reliable',\n",
       " 'making',\n",
       " 'world',\n",
       " 'come',\n",
       " 'sorry',\n",
       " 'isnt',\n",
       " 'reference',\n",
       " 'mean',\n",
       " 'continue',\n",
       " 'try',\n",
       " 'references',\n",
       " 'found',\n",
       " 'doing',\n",
       " 'text',\n",
       " 'great',\n",
       " 'leave',\n",
       " 'says',\n",
       " 'got',\n",
       " 'probably',\n",
       " 'english',\n",
       " 'original',\n",
       " 'every',\n",
       " '1',\n",
       " 'simply',\n",
       " 'word',\n",
       " 'users',\n",
       " 'fair',\n",
       " 'hello',\n",
       " 'either',\n",
       " 'check',\n",
       " 'least',\n",
       " 'adding',\n",
       " 'ip',\n",
       " 'show',\n",
       " 'site',\n",
       " 'state',\n",
       " 'else',\n",
       " 'delete',\n",
       " 'consensus',\n",
       " 'enough',\n",
       " 'request',\n",
       " 'far',\n",
       " 'opinion',\n",
       " 'created',\n",
       " 'around',\n",
       " 'life',\n",
       " 'day',\n",
       " 'between',\n",
       " 'through',\n",
       " 'example',\n",
       " 'view',\n",
       " 'yes',\n",
       " 'reverted',\n",
       " 'yet',\n",
       " 'etc',\n",
       " 'id',\n",
       " 'matter',\n",
       " 'shit',\n",
       " 'u',\n",
       " 'war',\n",
       " 'notable',\n",
       " 'contributions',\n",
       " 'given',\n",
       " 'thought',\n",
       " 'material',\n",
       " 'book',\n",
       " 'admin',\n",
       " 'write',\n",
       " 'post',\n",
       " 'down',\n",
       " 'account',\n",
       " 'clearly',\n",
       " 'having',\n",
       " 'encyclopedia',\n",
       " 'lot',\n",
       " 'support',\n",
       " 'real',\n",
       " 'bad',\n",
       " 'message',\n",
       " 'needs',\n",
       " 'images',\n",
       " 'tell',\n",
       " 'seem',\n",
       " 'called',\n",
       " 'maybe',\n",
       " 'evidence',\n",
       " 'instead',\n",
       " 'ever',\n",
       " '3',\n",
       " 'correct',\n",
       " 'saying',\n",
       " 'clear',\n",
       " 'always',\n",
       " 'number',\n",
       " 'important',\n",
       " 'further',\n",
       " 'quite',\n",
       " 'perhaps',\n",
       " 'old',\n",
       " '—',\n",
       " 'true',\n",
       " 'until',\n",
       " 'hate',\n",
       " 'states',\n",
       " 'whether',\n",
       " 'consider',\n",
       " 'written',\n",
       " 'claim',\n",
       " 'language',\n",
       " 'media',\n",
       " 'bit',\n",
       " 'once',\n",
       " 'guidelines',\n",
       " 'term',\n",
       " 'criteria',\n",
       " 'research',\n",
       " 'nigger',\n",
       " 'version',\n",
       " 'times',\n",
       " 'website',\n",
       " 'getting',\n",
       " 'fucking',\n",
       " 'theres',\n",
       " 'review',\n",
       " 'mention',\n",
       " 'pov',\n",
       " 'oh',\n",
       " 'makes',\n",
       " 'several',\n",
       " 'revert',\n",
       " 'considered',\n",
       " 'changes',\n",
       " 'cannot',\n",
       " 'words',\n",
       " 'idea',\n",
       " 'title',\n",
       " 'suck',\n",
       " 'address',\n",
       " 'notice',\n",
       " 'based',\n",
       " 'top',\n",
       " 'following',\n",
       " 'current',\n",
       " 'each',\n",
       " 'listed',\n",
       " 'means',\n",
       " 'possible',\n",
       " 'group',\n",
       " 'facts',\n",
       " 'regarding',\n",
       " 'care',\n",
       " 'rules',\n",
       " 'second',\n",
       " 'main',\n",
       " 'template',\n",
       " 'mentioned',\n",
       " 'general',\n",
       " 'year',\n",
       " 'attack',\n",
       " 'kind',\n",
       " 'whole',\n",
       " 'course',\n",
       " 'statement',\n",
       " 'left',\n",
       " 'hey',\n",
       " 'date',\n",
       " 'include',\n",
       " 'seen',\n",
       " 'three',\n",
       " 'issues',\n",
       " 'start',\n",
       " 'ass',\n",
       " 'ok',\n",
       " 'end',\n",
       " 'wikipedias',\n",
       " 'call',\n",
       " 'less',\n",
       " 'topic',\n",
       " 'gay',\n",
       " 'suggest',\n",
       " 'man',\n",
       " 'including',\n",
       " 'happy',\n",
       " 'sense',\n",
       " 'provide',\n",
       " 'create',\n",
       " 'big',\n",
       " 'days',\n",
       " 'myself',\n",
       " 'american',\n",
       " 'redirect',\n",
       " 'known',\n",
       " 'sentence',\n",
       " 'move',\n",
       " 'appropriate',\n",
       " 'changed',\n",
       " 'love',\n",
       " 'notability',\n",
       " 'explain',\n",
       " 'started',\n",
       " 'included',\n",
       " 'removing',\n",
       " 'project',\n",
       " 'anyway',\n",
       " 'info',\n",
       " 'mind',\n",
       " 'school',\n",
       " '2005',\n",
       " 'next',\n",
       " 'looking',\n",
       " 'although',\n",
       " 'picture',\n",
       " 'relevant',\n",
       " 'four',\n",
       " 'die',\n",
       " 'sign',\n",
       " 'answer',\n",
       " 'style',\n",
       " 'away',\n",
       " 'per',\n",
       " 'order',\n",
       " 'warning',\n",
       " 'wont',\n",
       " 'recent',\n",
       " 'youve',\n",
       " 'interest',\n",
       " 'community',\n",
       " 'summary',\n",
       " 'later',\n",
       " 'lol',\n",
       " 'claims',\n",
       " 'currently',\n",
       " 'discuss',\n",
       " 'interested',\n",
       " 'policies',\n",
       " 'attacks',\n",
       " 'especially',\n",
       " 'wish',\n",
       " 'wrote',\n",
       " 'able',\n",
       " 'specific',\n",
       " 'public',\n",
       " 'taken',\n",
       " 'writing',\n",
       " 'neutral',\n",
       " 'full',\n",
       " 'names',\n",
       " 'within',\n",
       " '4',\n",
       " 'position',\n",
       " 'related',\n",
       " 'below',\n",
       " 'line',\n",
       " 'wanted',\n",
       " 'during',\n",
       " 'appears',\n",
       " 'stuff',\n",
       " 'certainly',\n",
       " 'official',\n",
       " 'nice',\n",
       " 'itself',\n",
       " 'faith',\n",
       " 'everyone',\n",
       " 'wasnt',\n",
       " 'live',\n",
       " 'report',\n",
       " 'completely',\n",
       " 'according',\n",
       " 'unless',\n",
       " 'common',\n",
       " 'pretty',\n",
       " 'country',\n",
       " 'everything',\n",
       " 'looks',\n",
       " 'due',\n",
       " 'single',\n",
       " 'hes',\n",
       " 'process',\n",
       " 'contribs',\n",
       " 'news',\n",
       " 'involved',\n",
       " 'god',\n",
       " 'fat',\n",
       " 'therefore',\n",
       " 'obviously',\n",
       " 'remember',\n",
       " 'lead',\n",
       " 'hard',\n",
       " 'admins',\n",
       " 'came',\n",
       " 'edited',\n",
       " 'web',\n",
       " 'stay',\n",
       " 'learn',\n",
       " 'response',\n",
       " 'future',\n",
       " 'past',\n",
       " 'asked',\n",
       " 'truth',\n",
       " 'reading',\n",
       " 'power',\n",
       " '2006',\n",
       " 'stupid',\n",
       " 'entry',\n",
       " 'quote',\n",
       " 'posted',\n",
       " 'nor',\n",
       " 'talking',\n",
       " 'placed',\n",
       " '5',\n",
       " 'ago',\n",
       " 'similar',\n",
       " 'email',\n",
       " 'game',\n",
       " 'published',\n",
       " 'exactly',\n",
       " 'today',\n",
       " 'reasons',\n",
       " 'paragraph',\n",
       " 'faggot',\n",
       " 'city',\n",
       " 'argument',\n",
       " 'whatever',\n",
       " 'system',\n",
       " 'working',\n",
       " 'false',\n",
       " 'sandbox',\n",
       " 'moron',\n",
       " 'political',\n",
       " 'noticed',\n",
       " 'useful',\n",
       " 'havent',\n",
       " 'guy',\n",
       " 'high',\n",
       " 'regards',\n",
       " 'united',\n",
       " 'guess',\n",
       " 'appreciate',\n",
       " 'particular',\n",
       " 'deleting',\n",
       " 'form',\n",
       " 'books',\n",
       " 'government',\n",
       " 'dispute',\n",
       " 'five',\n",
       " 'british',\n",
       " 'reverting',\n",
       " 'major',\n",
       " 'problems',\n",
       " 'national',\n",
       " 'party',\n",
       " 'provided',\n",
       " 'often',\n",
       " 'ones',\n",
       " 'become',\n",
       " 'lets',\n",
       " 'tried',\n",
       " 'side',\n",
       " 'administrator',\n",
       " 'along',\n",
       " 'reply',\n",
       " 'almost',\n",
       " 'needed',\n",
       " 'stated',\n",
       " 'rule',\n",
       " 'took',\n",
       " 'search',\n",
       " 'knowledge',\n",
       " 'banned',\n",
       " 'cheers',\n",
       " 'taking',\n",
       " 'vandalize',\n",
       " '–',\n",
       " 'certain',\n",
       " '2007',\n",
       " 'username',\n",
       " 'fine',\n",
       " 'status',\n",
       " 'law',\n",
       " 'points',\n",
       " 'company',\n",
       " 'otherwise',\n",
       " 'uploaded',\n",
       " 'terms',\n",
       " 'explanation',\n",
       " 'generally',\n",
       " 'sort',\n",
       " 'entire',\n",
       " 'shows',\n",
       " 'description',\n",
       " 'whats',\n",
       " 'recently',\n",
       " 'follow',\n",
       " 'guys',\n",
       " '2008',\n",
       " 'likely',\n",
       " 'film',\n",
       " 'present',\n",
       " 'aware',\n",
       " 'saw',\n",
       " 'definition',\n",
       " 'cited',\n",
       " 'alone',\n",
       " 'google',\n",
       " 'music',\n",
       " 'soon',\n",
       " 'indeed',\n",
       " 'decide',\n",
       " 'ban',\n",
       " 'wp',\n",
       " 'appear',\n",
       " 'views',\n",
       " 'week',\n",
       " 'open',\n",
       " 'citation',\n",
       " 'contributing',\n",
       " 'actual',\n",
       " 'set',\n",
       " 'interesting',\n",
       " 'piece',\n",
       " 'c',\n",
       " 'short',\n",
       " 'white',\n",
       " 'told',\n",
       " 'theory',\n",
       " 'area',\n",
       " 'improve',\n",
       " 'external',\n",
       " 'small',\n",
       " 'story',\n",
       " 'contact',\n",
       " 'simple',\n",
       " '2004',\n",
       " 'various',\n",
       " 'allowed',\n",
       " 'moved',\n",
       " 'test',\n",
       " 'internet',\n",
       " 'obvious',\n",
       " 'family',\n",
       " 'band',\n",
       " 'attention',\n",
       " 'arent',\n",
       " 'proposed',\n",
       " 'jew',\n",
       " 'themselves',\n",
       " 'members',\n",
       " 'wouldnt',\n",
       " 'result',\n",
       " 'disagree',\n",
       " 'thus',\n",
       " 'cunt',\n",
       " 'went',\n",
       " 'type',\n",
       " 'sites',\n",
       " 'ie',\n",
       " 'context',\n",
       " 'mr',\n",
       " 'previous',\n",
       " 'nonsense',\n",
       " 'actions',\n",
       " 'tags',\n",
       " 'cite',\n",
       " 'works',\n",
       " '10',\n",
       " 'citations',\n",
       " 'jews',\n",
       " 'university',\n",
       " 're',\n",
       " 'enjoy',\n",
       " 'conflict',\n",
       " 'hours',\n",
       " 'shouldnt',\n",
       " 'proper',\n",
       " 'bias',\n",
       " 'category',\n",
       " 'job',\n",
       " 'longer',\n",
       " 'file',\n",
       " 'together',\n",
       " 'hell',\n",
       " 'sourced',\n",
       " 'sucks',\n",
       " 'addition',\n",
       " 'happened',\n",
       " 'avoid',\n",
       " 'automatically',\n",
       " 'author',\n",
       " 'valid',\n",
       " 'black',\n",
       " 'creating',\n",
       " 'deal',\n",
       " 'worked',\n",
       " 'npov',\n",
       " 'goes',\n",
       " 'himself',\n",
       " 'seriously',\n",
       " 'john',\n",
       " 'death',\n",
       " 'proof',\n",
       " 'respect',\n",
       " 'bitch',\n",
       " 'science',\n",
       " 'human',\n",
       " 'biased',\n",
       " 'comes',\n",
       " 'helpful',\n",
       " 'large',\n",
       " 'accepted',\n",
       " 'available',\n",
       " 'exist',\n",
       " 'series',\n",
       " 'tildes',\n",
       " 'opinions',\n",
       " 'hand',\n",
       " '6',\n",
       " 'indicate',\n",
       " 'sections',\n",
       " 'rights',\n",
       " 'necessary',\n",
       " 'act',\n",
       " 'meaning',\n",
       " 'attempt',\n",
       " 'accept',\n",
       " 'personally',\n",
       " 'statements',\n",
       " 'violation',\n",
       " 'months',\n",
       " 'criticism',\n",
       " 'accurate',\n",
       " 'action',\n",
       " 'usually',\n",
       " 'unblock',\n",
       " 'german',\n",
       " 'pig',\n",
       " 'cause',\n",
       " 'yeah',\n",
       " 'living',\n",
       " 'copy',\n",
       " 'debate',\n",
       " 'upon',\n",
       " 'assume',\n",
       " 'july',\n",
       " 'calling',\n",
       " 'standard',\n",
       " 'video',\n",
       " 'play',\n",
       " 'rest',\n",
       " 'tagged',\n",
       " 'doubt',\n",
       " 'sex',\n",
       " 'multiple',\n",
       " 'theyre',\n",
       " 'historical',\n",
       " 'serious',\n",
       " 'details',\n",
       " 'dick',\n",
       " 'youll',\n",
       " 'separate',\n",
       " 'manual',\n",
       " 'record',\n",
       " 'blocking',\n",
       " 'afd',\n",
       " 'explaining',\n",
       " 'situation',\n",
       " 'refer',\n",
       " 'wikiproject',\n",
       " 'heard',\n",
       " 'online',\n",
       " 'level',\n",
       " 'fix',\n",
       " 'asking',\n",
       " '7',\n",
       " 'complete',\n",
       " 'speak',\n",
       " 'lack',\n",
       " 'messages',\n",
       " 'none',\n",
       " 'prove',\n",
       " 'third',\n",
       " 'subjects',\n",
       " 'church',\n",
       " 'apparently',\n",
       " '2009',\n",
       " 'south',\n",
       " 'rationale',\n",
       " 'bullshit',\n",
       " 'data',\n",
       " 'directly',\n",
       " 'august',\n",
       " 'period',\n",
       " 'legal',\n",
       " 'behavior',\n",
       " 'difference',\n",
       " 'contribute',\n",
       " 'greek',\n",
       " 'huge',\n",
       " 'gets',\n",
       " 'wikipedian',\n",
       " 'couple',\n",
       " 'supposed',\n",
       " 'among',\n",
       " 'early',\n",
       " 'except',\n",
       " 'march',\n",
       " 'close',\n",
       " 'quality',\n",
       " 'space',\n",
       " 'meant',\n",
       " 'countries',\n",
       " 'run',\n",
       " 'team',\n",
       " 'uses',\n",
       " 'military',\n",
       " 'b',\n",
       " 'changing',\n",
       " 'existing',\n",
       " 'specifically',\n",
       " 'significant',\n",
       " '2010',\n",
       " 'pillars',\n",
       " 'fish',\n",
       " 'incorrect',\n",
       " 'culture',\n",
       " 'described',\n",
       " 'produce',\n",
       " 'jewish',\n",
       " '24',\n",
       " 'uk',\n",
       " 'disruptive',\n",
       " 'd',\n",
       " 'field',\n",
       " 'error',\n",
       " 'india',\n",
       " 'head',\n",
       " 'primary',\n",
       " 'friend',\n",
       " 'earlier',\n",
       " 'sometimes',\n",
       " 'outside',\n",
       " '20',\n",
       " 'purpose',\n",
       " 'administrators',\n",
       " 'modern',\n",
       " 'photo',\n",
       " 'table',\n",
       " 'particularly',\n",
       " 't',\n",
       " 'release',\n",
       " 'gave',\n",
       " 'box',\n",
       " 'cases',\n",
       " 'inclusion',\n",
       " 'born',\n",
       " 'pictures',\n",
       " 'readers',\n",
       " 'june',\n",
       " 'character',\n",
       " 'vote',\n",
       " 'okay',\n",
       " 'groups',\n",
       " 'anonymous',\n",
       " 'abuse',\n",
       " 'arguments',\n",
       " 'business',\n",
       " 'shall',\n",
       " 'sock',\n",
       " 'tutorial',\n",
       " 'january',\n",
       " 'friends',\n",
       " 'numbers',\n",
       " 'control',\n",
       " 'thinking',\n",
       " 'member',\n",
       " 'linked',\n",
       " 'happen',\n",
       " 'reported',\n",
       " 'contest',\n",
       " 'coming',\n",
       " 'takes',\n",
       " 'concerns',\n",
       " 'allow',\n",
       " 'wait',\n",
       " 'majority',\n",
       " 'giving',\n",
       " '8',\n",
       " 'bring',\n",
       " 'eg',\n",
       " 'worth',\n",
       " 'kill',\n",
       " 'totally',\n",
       " 'red',\n",
       " 'force',\n",
       " 'decided',\n",
       " 'discussed',\n",
       " 'house',\n",
       " 'finally',\n",
       " 'absolutely',\n",
       " 'putting',\n",
       " 'scientific',\n",
       " 'respond',\n",
       " 'mistake',\n",
       " 'decision',\n",
       " 'de',\n",
       " 'lost',\n",
       " 'entirely',\n",
       " '100',\n",
       " 'towards',\n",
       " 'merely',\n",
       " 'home',\n",
       " 'neither',\n",
       " 'dear',\n",
       " 'independent',\n",
       " 'international',\n",
       " 'song',\n",
       " 'balls',\n",
       " 'wants',\n",
       " 'possibly',\n",
       " 'unsigned',\n",
       " 'million',\n",
       " 'irrelevant',\n",
       " 'standards',\n",
       " 'april',\n",
       " '12',\n",
       " 'press',\n",
       " 'figure',\n",
       " 'organization',\n",
       " 'looked',\n",
       " 'inappropriate',\n",
       " 'chance',\n",
       " 'posting',\n",
       " 'population',\n",
       " 'advice',\n",
       " 'posts',\n",
       " 'north',\n",
       " 'events',\n",
       " 'unfortunately',\n",
       " 'named',\n",
       " 'album']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b9f21dde-0d8b-4662-8ede-b8ba7160e91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([288, 263, 306,   9, 275])>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer(\"Hello World, life is great\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b448b2a-3e85-41a1-a29a-76f51f20962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text = vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6d73b887-0fee-4564-b7aa-e5c5ccc7b2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(159571, 100), dtype=int64, numpy=\n",
       "array([[645,  76,   2, ...,   0,   0,   0],\n",
       "       [  1,  54,   1, ...,   0,   0,   0],\n",
       "       [425, 441,  70, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  1,   1, 383, ...,   0,   0,   0],\n",
       "       [  5,  12, 534, ...,   0,   0,   0],\n",
       "       [  5,   8, 130, ...,   0,   0,   0]])>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db536f2c-28f7-41f9-aee4-8e16cf193693",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8) # helps prevent bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "94961387-988c-40b1-8f81-3f8c388f5f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_X, batch_y = dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6173b50e-f038-4b23-b23f-205d7adcb75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  1, 111,  14, ...,   1,   3, 247],\n",
       "        [ 64,  33,   7, ...,   0,   0,   0],\n",
       "        [ 48, 198,   5, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  1,   1,   1, ...,   0,   0,   0],\n",
       "        [  2,  24,   1, ...,   1, 107,  46],\n",
       "        [  1, 441,   8, ...,   0,   0,   0]]),\n",
       " (16, 100))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X, batch_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7750ddf6-cf28-46d9-be47-f86aa3ad2b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]]),\n",
       " (16, 6))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y, batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cc155e7d-cb97-4e54-a79f-92cc51522d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9974"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0873be4f-6ac2-47cb-92eb-3c72536afb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.7))\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c0ceb02c-21d2-44e4-8030-b7415fbe9a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  1,  52, 165, ...,   0,   0,   0],\n",
       "        [ 50, 249, 229, ..., 318,  40,  33],\n",
       "        [ 49, 234,   8, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  1,   1,   4, ...,  47,  17, 461],\n",
       "        [563,   1,   8, ...,   0,   0,   0],\n",
       "        [  2, 281,   1, ...,   0,   0,   0]]),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0],\n",
       "        [1, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = train.as_numpy_iterator()\n",
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed05df8-5551-4643-974f-a3c24d1814af",
   "metadata": {},
   "source": [
    "### 2. Create Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ef8cfa1c-bc7c-4fad-b6d1-b5cee70c3f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4a40618f-77ed-4351-8d9a-68b61ea643bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Create the embedding layer\n",
    "model.add(Embedding(MAX_FEATURES+1, 16))\n",
    "# LSTM Layer\n",
    "model.add(LSTM(8, activation='tanh'))\n",
    "# Feature extractor fully connected layers\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "# Final layer\n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "93c7432d-3b6c-4d41-b6ba-0d8fe93b15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7267cddb-ae43-441f-bc9d-d90a2cc1666e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, None, 16)          16016     \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 8)                 800       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 16)                144       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,134\n",
      "Trainable params: 18,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "37a6d227-cd05-40bd-889e-ee89c476c9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6981/6981 [==============================] - 371s 53ms/step - loss: 0.1405 - val_loss: 0.1088\n",
      "Epoch 2/10\n",
      "6981/6981 [==============================] - 353s 50ms/step - loss: 0.1294 - val_loss: 0.1273\n",
      "Epoch 3/10\n",
      "6981/6981 [==============================] - 387s 55ms/step - loss: 0.1127 - val_loss: 0.1000\n",
      "Epoch 4/10\n",
      "6981/6981 [==============================] - 442s 63ms/step - loss: 0.1175 - val_loss: 0.1119\n",
      "Epoch 5/10\n",
      "6981/6981 [==============================] - 495s 71ms/step - loss: 0.0989 - val_loss: 0.1062\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=2,          # Stop training if no improvement after 3 epochs\n",
    "    restore_best_weights=True  # Restore the best weights after stopping\n",
    ")\n",
    "history = model.fit(train, epochs=10, validation_data=val, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "68c76f6f-fe09-446c-a9d6-25694b7e1d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.1405181884765625,\n",
       "  0.12940078973770142,\n",
       "  0.11269721388816833,\n",
       "  0.1174813061952591,\n",
       "  0.09888029843568802],\n",
       " 'val_loss': [0.10877025127410889,\n",
       "  0.1273379623889923,\n",
       "  0.09998662769794464,\n",
       "  0.1119154691696167,\n",
       "  0.10620532929897308]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9eb5a93a-e97e-4a3f-9932-e093c1bab208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6c693bfb-28c5-4324-bbfe-3d5f040d4a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed99a4ca-02e5-4196-a957-85eceb4c0ef8",
   "metadata": {},
   "source": [
    "### 3. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e6601353-e1d4-4024-bf5f-b65162d3037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
       "array([  7,   1, 397,   8,  74, 164,   3,   1,   7,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0])>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = vectorizer('You freaking suck! I am going to hit you!')\n",
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "aa8350f8-3f16-4e2a-8911-d8e79c64504d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(np.expand_dims(input_text, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "58fa60da-f1ef-4ebd-8978-e8f19c4b8277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39248085, 0.05081593, 0.22581889, 0.01453779, 0.23410784,\n",
       "        0.03990347]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6bf06e61-fe80-4c29-9982-1048c6a54465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "72fcccbc-920a-47bd-8851-7ff6d5371fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4f2b1efc-59b7-4eaf-ad92-0833c74a06e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  9,  41,  30, ...,   0,   0,   0],\n",
       "        [ 94,   8,  74, ...,   0,   0,   0],\n",
       "        [196,  52,   6, ...,   1, 364,  10],\n",
       "        ...,\n",
       "        [  8, 201,  65, ...,   0,   0,   0],\n",
       "        [  1,  34,   2, ...,   0,   0,   0],\n",
       "        [202,   8,  88, ...,   0,   0,   0]]),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ddde4b7f-d11f-4ac1-8c50-3f4e57e11a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ef9642ac-c2d5-40b8-9eb4-165b7370b310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(batch_X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde1513-7824-4fd3-b123-7d42f9f3f4e6",
   "metadata": {},
   "source": [
    "### 4. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1e1cf1df-ac34-4a79-94a4-3f0877f3f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e17a28aa-fd67-4cbf-9a4c-d831143f5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dc15eac7-fb6d-4b56-ac84-594716ca98b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    # Unpack the batch\n",
    "    X_true, y_true = batch\n",
    "    # Make a prediction\n",
    "    yhat = model.predict(X_true)\n",
    "\n",
    "    # Flatten the predictions\n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "\n",
    "    pre.update_state(y_true, yhat)\n",
    "    re.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "77b0b667-507e-416c-bc4f-595f30b0b12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8461538553237915, Recall: 0.0032650637440383434, Accuracy:0.27382147312164307\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {pre.result().numpy()}, Recall: {re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d58687-1078-4ae9-b59b-49b0190fee7a",
   "metadata": {},
   "source": [
    "### 5. Test and Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "45130620-d349-412c-9cc6-daa8664f7211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: jinja2 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (3.1.4)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from gradio) (4.2.0)\n",
      "Collecting fastapi<1.0 (from gradio)\n",
      "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.3.0 (from gradio)\n",
      "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from gradio) (0.27.0)\n",
      "Collecting huggingface-hub>=0.19.3 (from gradio)\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from gradio) (3.9.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from gradio) (1.26.4)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: packaging in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from gradio) (10.4.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from gradio) (2.2.3)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fsspec (from gradio-client==1.3.0->gradio)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n",
      "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
      "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: certifi in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Collecting filelock (from huggingface-hub>=0.19.3->gradio)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.19.3->gradio)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-13.9.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aditya/miniconda3/envs/dl-env/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
      "Downloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
      "Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m02\u001b[0m\n",
      "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Downloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n",
      "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading rich-13.9.2-py3-none-any.whl (242 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pydub, websockets, uvicorn, tqdm, tomlkit, shellingham, semantic-version, ruff, python-multipart, pydantic-core, orjson, mdurl, importlib-resources, fsspec, filelock, ffmpy, annotated-types, aiofiles, starlette, pydantic, markdown-it-py, huggingface-hub, rich, gradio-client, fastapi, typer, gradio\n",
      "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 fastapi-0.115.0 ffmpy-0.4.0 filelock-3.16.1 fsspec-2024.9.0 gradio-4.44.1 gradio-client-1.3.0 huggingface-hub-0.25.1 importlib-resources-6.4.5 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.10.7 pydantic-2.9.2 pydantic-core-2.23.4 pydub-0.25.1 python-multipart-0.0.12 rich-13.9.2 ruff-0.6.9 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.38.6 tomlkit-0.12.0 tqdm-4.66.5 typer-0.12.5 uvicorn-0.31.0 websockets-12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "63aa5f5e-8825-41b0-80ba-94c772470482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eb96d379-e011-4ca5-9413-7e0f06097f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('toxicity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6e061017-bffb-4101-b7df-ee345ecf46ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('toxicity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "25401d85-dd03-4a64-b332-501536c595fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = vectorizer('hey i freaken hate you!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "76026de8-dda6-409f-af54-2dff7c29a9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 679ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(np.expand_dims(input_str,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c4c81dad-9006-46c3-be29-c13b53e93f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39248076, 0.05081585, 0.22581874, 0.01453778, 0.2341077 ,\n",
       "        0.03990344]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "93430c4f-954f-4c10-a802-b44e5037fd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ac9caf61-a290-4eae-94fa-e9b676e54843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comment(comment):\n",
    "    vectorized_comment = vectorizer([comment])\n",
    "    results = model.predict(vectorized_comment)\n",
    "    text = ''\n",
    "    for idx, col in enumerate(df.columns[2:]):\n",
    "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "85cc735b-daa6-4984-b9d8-348420c46e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn=score_comment,\n",
    "                        inputs=gr.Textbox(lines=2, placeholder='Comment to score'),\n",
    "                        outputs='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e1ce2a59-70d9-4172-8982-94f005b62016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://f8cab8e914222ced66.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://f8cab8e914222ced66.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91847bca-9ca3-49f6-b6c7-a32ae6e76c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
